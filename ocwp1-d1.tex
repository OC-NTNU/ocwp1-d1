% Notes on writing:
% 
% * Use one sentence per line (no hard word wrapping), which makes merging different versions a lot easier.
% * Use \EM{}, \PO{} or \EA{} to add your personal comments or todos.
% * Using Git, the easiest way is probably to create your own branch and merge updates into the master branch. For Mac, see https://mac.github.com



% From DoW (603773_DOW_2013-08-05[3].pdf, p.17):
%
% D1.3) Report on LBKD model and method in the climate change domain: 
% A survey of the key publications, approaches, software and resources on Literature-Based Knowledge Discovery will be conducted. 
% In addition, any work in this area specifically related to climate change will be surveyed. 
% This will result in survey paper on LBKD in the field of climate change [month 6]


\documentclass[11pt,twoside,a4paper]{report}
\usepackage{natbib}
\usepackage{graphicx}

\usepackage{todonotes}
% To hide all notes use 
% \usepackage[disable]{todonotes}


\newcommand{\EM}[1]{\todo[inline,author=EM,color=yellow]{#1}}
\newcommand{\PO}[1]{\todo[inline,author=PO,color=blue]{#1}}
\newcommand{\EA}[1]{\todo[inline,author=EA,color=green]{#1}}


\begin{document}

\title{Deliverable D1.1:\\ Literature-based Knowledge Discovery\\in Climate, Marine and Environmental Science}
\author{Erwin Marsi, Pinar \"Ozt\"urk, Elias Aamot}
\date{April 2014}
\maketitle

\abstract{}

\chapter{Introduction}


\chapter{Text Mining}

\todo[inline]{Describe text mining, especially entity detection, relation extraction and event extraction in BioNLP}

There is a fast growing amount of \emph{structured data} in the form of very large databases, numerical data collections and log files, commonly referred to as \emph{Big Data} nowadays.
Data mining, also known as \emph{knowledge discovery}, is about the discovery of interesting patterns in huge data collections through computational analysis.
In addition, however, there is a parallel stream of so-called \emph{unstructured data} in the form of text.
This comprises traditional sources such as newspapers, books, magazines and journals, as well as new media such webpages (Wikepedia), blogs, social media (Facebook) and messaging (Twitter).
Data mining methods can not handle text as input.
Therefore text needs to be converted to some form of structured data first in order to perform data mining.
This is essentialy what \emph{text mining} is about: extracting structured information from text in order to discover patterns in huge text collections through computational analysis.
Text mining can therefore be regarded as a combination of information retrieval, information extraction, natural language processing and data mining.

Information retrieval (IR) addresses the task of searching a large document collection for documents that are relevent to a user's informational needs as expressed in a search query. 
The most common IR applications nowadays are web search engines which try to retrieve relevant text documents from the web, mostly webpages, on the basis of a number of keywords or phrases.
Specialized search engines exists for particular documents collections, for instance, to search scientific publications in the area of biomedicine.
IR is typically the first step in text mining in order to narrow down the set of relevant documents to a size managable for more in depth analysis.

Information extraction (IE) is the process of automatically extracting structured information from text.
What type of structured information is extracted depends on the application, but usually involves two broad types of information: \emph{entities} and \emph{relations}.
Entities are the things mentioned in the text.
These can be general like people, organisations, companies or places, but can also be domain-specific such as proteins, genes or drugs, organisms or anatomical parts.
Finding entities in text is called \emph{named entity recognition}.
Relations hold among pairs of entities.
For example, a company can buy or sell another company, a certain protein may interact with a certain gene, or a certain drug may cause a ceratin side effect.
Finding these relations in text is known as \emph{relation extraction}.  
Relations may be more complex than simple binary relations between pairs of entities.
They may involve multiple entities playing different roles, additional circumstances, or even relations between relations.
In this case, it is common to talk about \emph{events} and \emph{event extraction}.    

Natural language processing (NLP) concerns automatic analysis and ultimately understanding of language by computers, usually from an applied point of view.  
Natural languages such as English -- as opposed to artificial languages like programming languages -- are extremely complex and versatile symbolic systems that humans use to exchange information.
Language can convey many different types of information, ranging from simple facts to complex arguments or emotional states.
Notwithstanding tremendous progress in NLP, computers are still far from real understanding of language and currently manage a shallow understanding of meaning at best.
In practice, NLP for a specific domain, e.g. stock market reports or biomedical research articles, works significantly better than NLP for unrestricted domains, because domain-specific language use and knowledge can be exploited.
Hence NLP techniques and tools are often domain-specific.

IR usually relies on some forms of NLP.
Key word search, for instance, often involves a \emph{lemmatisation} step wich relates all morphological variants of a word to its stem.
For example, the verbs \emph{diving}, \emph{dives}, \emph{dove}, \emph{dived} are all linked to their base form \emph{dive}.
For many languages, this improves recall of relevant documents at the (slight) expense of precision.

IE usually depends on NLP to a much larger degree for linguistic analysis of the input text.
Common NLP techniques are \emph{part-of-speech tagging} (labeling tokens according to their word class such a noun, verb or preposition ), lemmatisation and syntactic parsing (analysis of the grammatical structure of sentences).
Linguistic annotations ofthe  text serve as input to algorithms for entity recognition and relation extraction, which can range from hand-written pattern matching rules to data-driven machine learning algorithms.
Like domain-specific NLP, IE is usually rather restricted in scope, that is, it targets a small subset of entities and relations of interest, ignoring all other meaning contained in the text.    

Even with these limitations to a particular domain and to particular aspects of meaning, computers still make many mistakes in processing text, misinterpreting text and failing to detect important information.
Despite all their limitations, computers have one major advantage over humans when it comes to reading text: processing power. 
Computers can process thousands or millions of documents in a relatively short time, something a human reader would never be able to match.
The main strenght of text mining thus comes from the ability to process big text data.
One of the challenges in this area is how best to combine the fast but shallow and noisy processing capabilities of text mining systems with the slow but deep language understanding capibilities of humans.

\section{Text Mining in Biology and Medicine}

The first and most active area for research on, and application of, text mining is that of scientific publications in biology and medicine, collectively referred to as \emph{biomedicine}.
The MEDLINE (Medical Literature Analysis and Retrieval System Online) is a bibliographic database which indexes most biomedical publications from over 5,5000 journals since the 1950s.  
It currently contains over 21 million records and grows at a rate of approximately three publications a minute.\EM{ref}
Even though it allows researchers to retrieve documents by means of keyword search, search queries may return thousands of hits and checking all of them for relevant information is practically infeasible.
Text mining tools can offer a solution.
They can be be used for task such as further filtering of documents, clustering similar documents, automatically extracting information of interest, summarizing information through text and/or visualisation, and discovering regularities or inconsistencies.

Generic text mining tools are not well-suited for biomedical text because of highly specialized language use (jargon). 
For example, many terms have a particular meaning or do not occur at all outside of biomedical texts.
Moreover, text mining is highly dependent on the type of application, because different goals require different methods and tools.
There are a couple of prototypical applications in biomedical text mining which have driven much of the research efforts and the development of tools and resources.
One instance is finding interactions among proteins in order to find biological pathways, which are series of actions among molecules giving rise to some product or a change in a cell.
Another instance is mining interations between drugs, or between a drugs and their side effects, with the goal of drug retargetting or repurposing, that is, finding new applications for existing drugs.

entity detection

normalization

relation extraction

event extraction


\section{Machine Readiing and Open Information Extraction}

\todo[inline]{NLU, open IE}

\citet{Etzioni2011Search}

\chapter{Literature-based Knowledge Discovery}

\todo[inline]{key publications, approaches, software and resources on Literature-Based Knowledge Discovery}

\todo[inline]{inference and reasoning, relation to GOFAI}

\chapter{Text mining in Climate, Marine and Environmental Science}

\todo[inline]{Text mining work in related areas, e.g. Kyoto, GeoDeepDive, Text Mining for Marine Ecological Genomics}

\chapter{Ongoing and future work} 

\todo[inline]{Brief description of our current work and plans on LBD}

\bibliographystyle{plainnat}
\bibliography{ocwp1_d1}

\end{document}
