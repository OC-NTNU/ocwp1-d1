
\chapter{Text Mining}

\todo[inline]{Describe text mining, especially entity detection, relation extraction and event extraction in BioNLP}

There is a fast growing amount of \emph{structured data} in the form of very large databases, numerical data collections, multimedia data and log files, commonly referred to as \emph{Big Data} nowadays.
Data mining, also known as \emph{knowledge discovery} from data, is about the discovery of interesting patterns in huge data collections through computational analysis.
In addition, however, there is a parallel stream of so-called \emph{unstructured data} in the form of text.
This comprises traditional sources such as newspapers, books, magazines and journals, as well as new media such webpages (Wikepedia), blogs, social media (Facebook) and messaging (Twitter).
Much of the collective knowledge of the human race is encoded in the form of text. 
Data mining methods can not handle text as input.
Therefore text needs to be converted to some form of structured data first in order to allow data mining.
This is essentialy what \emph{text mining} is about: extracting structured information from text in order to discover patterns in huge text collections through computer processing.

Text mining is applied in many different domains; for a recent overview see e.g. \citep{Aggarwal2012Mining,Weiss2012Fundamentals}.
Different domains require different approaches, techniques, tools and resources.
For example, opinion mining from social media is quite different from trend detection in financial markets. 
In this text we focus on text mining of scientfic literature to support knowledge discovery, of which literature-based discovery is a particular instance.
Text mining on scinetific literature is can be regarded as a combination of information retrieval, information extraction, natural language processing and data mining.

Information retrieval (IR) addresses the task of searching a large document collection for documents that are relevent to a user's informational needs as expressed in a search query \citep{ManningRaghavanSchutze:08}. 
The most common IR applications nowadays are web search engines which try to retrieve relevant text documents from the web, mostly webpages, on the basis of a number of keywords or phrases.
Specialized search engines exists for particular documents collections, for instance, to search scientific publications in the area of biomedicine (PUBMED).
IR is typically the first step in text mining in order to narrow down the set of relevant documents to a size managable for more in depth analysis.

Information extraction (IE) is the process of automatically extracting structured information from text \citep{Jiang2012Information}.
What type of structured information is extracted depends on the application, but usually involves two general types of information: \emph{entities} and \emph{relations}.
Entities are the things mentioned in the text.
These can be general like people, organisations, companies or places, but can also be domain-specific such as proteins, genes or drugs, organisms or anatomical parts.
Finding entities in text is called \emph{named entity recognition}.
Relations hold among pairs of entities.
For example, a company can \emph{buy} or \emph{sell} another company, a certain protein may \emph{interact} with a certain gene, or a certain drug may \emph{cause} a certain side effect.
Finding these relations in text is known as \emph{relation extraction}.  
Relations may be more complex than simple binary relations between pairs of entities.
They may involve multiple entities playing different roles, additional circumstances, or even relations between relations.
In this case, it is common to talk about \emph{events} and \emph{event extraction}.

Natural language processing (NLP) concerns automatic analysis of language by computers, usually from an applied point of view.  
Natural languages such as English or Chinese -- as opposed to artificial languages like programming languages -- are extremely complex and versatile symbolic systems that have evolved over time to enable humanes to exchange information.
Language can convey many different types of information, ranging from simple facts to complex arguments or emotional states.
Notwithstanding tremendous progress in NLP over te last decades, computers are still far from real understanding of language and currently manage a shallow understanding of meaning at best.
In practice, NLP for a specific domain, e.g. stock market reports or biomedical research articles, works significantly better than NLP for unrestricted input, because domain-specific language use and knowledge can be exploited to improve interpretation. 
Hence NLP techniques, tools and resources are often tied to a particular application domain.

Most IR systems rely to some extent on NLP.
Key word search, for instance, often involves a \emph{lemmatisation} step wich relates all morphological variants of a word to its stem.
For example, the verbs \emph{diving}, \emph{dives}, \emph{dove}, \emph{dived} are all linked to their base form \emph{dive}.
For many languages, this improves recall of relevant documents at the (slight) expense of precision.
More advanced NLP techniques are keyword expansion with automatically learned synonymns and word sense disambiguation for keywords with more than one possible interpretation.  

IE tends to be highly dependent on NLP for linguistic analysis and interpretation of the input text prior to actual extraction.
Common NLP techniques are \emph{part-of-speech tagging} (labeling tokens according to their word class such a noun, verb, preposition, etc.), lemmatisation and syntactic parsing (analysis of the grammatical structure of sentences).
The resulting linguistic annotations of the text serve as input to the algorithms for entity recognition and relation extraction, which can range from hand-written pattern matching rules to data-driven machine learning algorithms.
Like domain-specific NLP, IE is usually rather restricted in scope, that is, it targets a small subset of entities and relations of interest in the given domain, ignoring all other meaning contained in the text.    

Even with these limitations to a particular domain and to particular aspects of meaning, computers still make many mistakes in processing text, misinterpreting text and failing to detect important information.
Despite all their limitations, computers have one major advantage over humans when it comes to reading text: processing power. 
Computers can process thousands or millions of documents in a relatively short time, something a human reader would never be able to match.
The main strenght of text mining thus comes from the ability to process big text data.
One of the challenges in this area is how best to combine the fast but shallow and noisy processing capabilities of text mining systems with the slow but deep language understanding capibilities of humans.

\section{Text Mining in Biology and Medicine}
\label{sec:tm-biomed}

The first and most active area for research on, and application of, text mining is that of scientific publications in fields of biology and medicine, collectively referred to as \emph{biomedicine}.
One of the main reasons for this is the volume and rate of publications in biomedicine.
The MEDLINE (Medical Literature Analysis and Retrieval System Online) is a bibliographic database which indexes most biomedical publications from over 5,5000 journals since the 1950s.  
It currently contains over 21 million records and grows at a rate of approximately three publications a minute.\EM{ref}
Even though it allows researchers to retrieve documents by means of keyword search, search queries may return thousands of hits and checking all of them for relevant information is practically infeasible.
Text mining tools can offer a solution.
They can be be used for task such as further filtering of documents, clustering similar documents, automatically extracting information of interest, summarizing information through text and/or visualisation, and discovering regularities or inconsistencies.

There exist many excellent survey and review articles about text mining in biomedicine, including
\citep{Neves2012Survey,Simpson2012Biomedical,Andronis2011Literature,Ananiadou2010Event,RodriguezEsteban2009Biomedical,Zweigenbaum2009Advanced,Cohen2008Getting,Zweigenbaum2007Frontiers,Ananiadou2006,Erhardt2006Status,JenEA06,Spasic2005Text,Cohen2005Survey,Krauthammer2004Term,Blake2011Text}.
Since we do not want to duplicate these efforts with yet another survey, our discussion here is limited to a brief summary of those aspects related to literature-based knowledge discovery.  

Generic text mining tools are not well-suited for biomedical text because of highly specialized language use (jargon). 
For example, many terms have a particular meaning or do not occur at all outside of biomedical texts.
Moreover, text mining is highly dependent on the type of application, because different goals require different methods and tools.
There are a couple of prototypical applications in biomedical text mining which have driven much of the research efforts and the development of tools and resources.
One instance is finding interactions among proteins in order to find biological pathways, which are series of actions among molecules giving rise to some product or a change in a cell.
Another instance is mining interations between drugs, or between a drugs and their side effects, with the goal of drug retargetting or repurposing, that is, finding new applications for existing drugs.

entity detection

normalization

relation extraction

event extraction


\section{Machine Reading and Open Information Extraction}

\todo[inline]{NLU, open IE}

\citet{Etzioni2011Search}

From DeepDive:
Knowledge-base construction (KBC) is the process of pop-
ulating a knowledge base (KB) with facts (or assertions)
extracted from text. It has recently received tremendous
interest from academia, e.g., CMU's NELL [2] and MPI's
YAGO [7,9], and from industry, e.g., IBM's DeepQA [5] and
Microsoft's EntityCube [16]. 


\todo[inline]{inference and reasoning, relation to GOFAI}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "ocwp1-d1"
%%% End: 